{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90cbe14f-6a7c-43da-984d-ca8fd255b870",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n",
      "{\n",
      "  \"shell_port\": 41581,\n",
      "  \"iopub_port\": 45443,\n",
      "  \"stdin_port\": 58121,\n",
      "  \"control_port\": 35167,\n",
      "  \"hb_port\": 38157,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"0b0d752f-181fdc9bfaaf3e0a1c7bb3ca\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"conda-root-py\",\n",
      "  \"jupyter_session\": \"/home/jupyter/starfire/notebooks/data_1_refi_deals.ipynb\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-2b7eeee3-1ce1-4824-a80b-5924cfaaed64.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "os.chdir('/home/jupyter')\n",
    "!pwd\n",
    "# # %cd \n",
    "# !pwd\n",
    "# (base) jupyter@starfire-1:~$ pip install jupyter-console\n",
    "# (base) jupyter@starfire-1:~$ !jupyter console --existing\n",
    "%connect_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e25274-9db7-440e-8353-5c229657bd2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import refinitiv.dataplatform as rdp\n",
    "\n",
    "%run ./starfire/notebooks/credentials.ipynb\n",
    "\n",
    "session = rdp.open_platform_session(\n",
    "    APP_KEY,\n",
    "    rdp.GrantPassword(\n",
    "        username = RDP_LOGIN,\n",
    "        password = RDP_PASSWORD\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2b1d9-2e61-45fc-840e-aa5bcc2e79b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date: 20220101, End Date: 20220103\n",
      "Downloading data from refinitiv...\n",
      "(287, 71)\n",
      "Master shape: (287, 71)\n",
      "Start Date: 20220104, End Date: 20220106\n",
      "Downloading data from refinitiv...\n",
      "(799, 71)\n",
      "Master shape: (1086, 71)\n",
      "Start Date: 20220107, End Date: 20220109\n",
      "Downloading data from refinitiv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR!!! An error occurred while requesting URL('https://api.refinitiv.com/data/datagrid/beta1/').\n",
      "     ReadTimeout('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: . Retrying for the range 20220107 to 20220109...\n",
      "Start Date: 20220107, End Date: 20220109\n",
      "Downloading data from refinitiv...\n",
      "(189, 71)\n",
      "Master shape: (1275, 71)\n",
      "Start Date: 20220110, End Date: 20220112\n",
      "Downloading data from refinitiv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_9864/4159335668.py:127: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  master_df = pd.concat([master_df, mnas], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(939, 71)\n",
      "Master shape: (2214, 71)\n",
      "Start Date: 20220113, End Date: 20220115\n",
      "Downloading data from refinitiv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR!!! An error occurred while requesting URL('https://api.refinitiv.com/data/datagrid/beta1/').\n",
      "     ReadTimeout('')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: . Retrying for the range 20220113 to 20220115...\n",
      "Start Date: 20220113, End Date: 20220115\n",
      "Downloading data from refinitiv...\n",
      "(490, 71)\n",
      "Master shape: (2704, 71)\n",
      "Start Date: 20220116, End Date: 20220118\n",
      "Downloading data from refinitiv...\n",
      "(557, 71)\n",
      "Master shape: (3261, 71)\n",
      "Start Date: 20220119, End Date: 20220121\n",
      "Downloading data from refinitiv...\n",
      "(726, 71)\n",
      "Master shape: (3987, 71)\n",
      "Start Date: 20220122, End Date: 20220124\n",
      "Downloading data from refinitiv...\n",
      "(279, 71)\n",
      "Master shape: (4266, 71)\n",
      "Start Date: 20220125, End Date: 20220127\n",
      "Downloading data from refinitiv...\n",
      "(876, 71)\n",
      "Master shape: (5142, 71)\n",
      "Start Date: 20220128, End Date: 20220130\n",
      "Downloading data from refinitiv...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize a BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Define your project, dataset, and table\n",
    "project_id = \"starfire-410116\"\n",
    "dataset_id = \"derived\"\n",
    "table_id = \"refinitiv_deals_3\"\n",
    "\n",
    "\n",
    "# Construct a reference to the target table\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "# Configure the load job to append data to the existing table\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND\n",
    ")\n",
    "\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initial start date\n",
    "start_date = datetime.strptime('20220101', '%Y%m%d')\n",
    " # 20000101 20210330 20210109\n",
    "\n",
    "# Define the interval (5 days) to avoid time outs\n",
    "interval = timedelta(days=2)\n",
    "\n",
    "# Initialize an empty list to store the date ranges\n",
    "date_ranges = []\n",
    "\n",
    "# Loop to create date intervals\n",
    "for _ in range(10000):  # Adjust the range to get the desired number of intervals\n",
    "    end_date = start_date + interval\n",
    "    date_ranges.append((start_date.strftime('%Y%m%d'), end_date.strftime('%Y%m%d')))\n",
    "    start_date = end_date + timedelta(days=1)\n",
    "\n",
    "j = 1\n",
    "N = 21\n",
    "# Print the date ranges\n",
    "for start, end in date_ranges:\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            print(f\"Start Date: {start}, End Date: {end}\")\n",
    "\n",
    "            print(\"Downloading data from refinitiv...\")\n",
    "\n",
    "            mna_screen = f'SCREEN(U(IN(DEALS)/*UNV:DEALSMNA*/),\\\n",
    "                        BETWEEN(TR.MnAAnnDate,{start},{end})/*dt:Date*/, \\\n",
    "                        CURN=USD)'\n",
    "\n",
    "\n",
    "            # input ipo screen results as instrument list and pull ipo attributes via fields from Eikon Data API. \n",
    "            mnas = rdp.get_data(mna_screen,['TR.MNASDCDealNumber',\n",
    "                                            'TR.MnAAnnDate', 'TR.MnARankValueIncNetDebt(Curn=USD,Scale=6)',\n",
    "                                            'TR.MnATarget', 'TR.MnATargetPermId',\n",
    "                                            'TR.MnATargetPriTickerSym',\n",
    "                                            'TR.MnATargetNation',\n",
    "                                            'TR.MnATargetMacroInd',\n",
    "                                            'TR.MnATargetMidInd',\n",
    "                                            'TR.MnAAcquiror',\n",
    "                                            'TR.MnAAcquirorPermId',\n",
    "                                            'TR.MnAAcquirorMacroInd',\n",
    "                                            'TR.MnAAcquirorMidInd',\n",
    "                                            'TR.MnAAcquirorNation',\n",
    "                                            'TR.MNADealId','TR.MnASynopsis',\n",
    "                                            'TR.MnAAcquirorPriHiTech',\n",
    "                                            'TR.MnAAcquirorPriTickerSym',\n",
    "                                            'TR.MnAAcquirorExchTicker(Concat=\"|\")',\n",
    "                                            'TR.MnAAcquirorUltParentPermID',\n",
    "                                            'TR.MnAHiTechGroup(Concat=\"|\")',\n",
    "                                            'TR.MnaAcquirorDate1DayPriorToAnn',\n",
    "                                            'TR.MnaAcquirorStockPrice1DayPriorToAnnInAcqCurr(Curn=USD)',\n",
    "                                            'TR.MnAAcquirorStockPriceOnAnn(Curn=USD)',\n",
    "                                            'TR.MnAAcquirorStockPrice1DayPostAnn(Curn=USD)',\n",
    "                                            'TR.MnASnP5001DayPreAnn',\n",
    "                                            'TR.MnASnP500AtAnnouncement',\n",
    "                                            'TR.MnASnP5001DayPostAnn',\n",
    "                                            'TR.MnATargetSDCCusip',\n",
    "                                            'TR.MnAAcquirorSDCCusip',\n",
    "                                            'TR.MnAAcquirorUltParentSDCCusip',\n",
    "                                            'TR.MnAValueOfCash(Curn=USD, Scale=6)',\n",
    "                                            'TR.MnAValueOfEarnout(Curn=USD, Scale=6)',\n",
    "                                            'TR.MnADealValue(Curn=USD, Scale=6)',\n",
    "                                            'TR.MnAAcquirorHiTech(Concat=\"|\")',\n",
    "                                            'TR.MnAAcquirorUltParentHiTech(Concat=\"|\")',\n",
    "                                            'TR.MnATargetPriHiTech',\n",
    "                                            'TR.MnAAcquirorMajorInd',\n",
    "                                            'TR.MnAAcquirorMajorIndGrp',\n",
    "                                            'TR.MnAAcquirorPriVEIC',\n",
    "                                            'TR.MnAMasterDealType',\n",
    "                                            'TR.MnADealType',\n",
    "                                            'TR.MnAType(Concat=\"|\")',\n",
    "                                            'TR.MnAAcquirorVeic(Concat=\"|\")',\n",
    "                                            'TR.MnAPurposeDescription',\n",
    "                                            'TR.MnAIsCrossBorder',\n",
    "                                            'TR.MnAAcquirorIsVentureFirm',\n",
    "                                            'TR.MnATargetPriVEIC',\n",
    "                                            'TR.MnATargetVeic(Concat=\"|\")',\n",
    "                                            'TR.MnAAcquirorBusDesc',\n",
    "                                            'TR.MnATargetBusDesc',\n",
    "                                            'TR.MnATargetExchTicker(Concat=\"|\")',\n",
    "                                            'TR.MnATargetUltParentSDCCusip',\n",
    "                                            'TR.MnATargetUltParentPriTickerSym',\n",
    "                                            'TR.MnATargetUltParentPermID',\n",
    "                                            'TR.MnAAcquirorUltParentPriTickerSym',\n",
    "                                            'TR.MnAAcquirorUltParentExchTicker(Concat=\"|\")',\n",
    "                                            'TR.MnATargetUltParentExchTicker(Concat=\"|\")',\n",
    "                                            'TR.MnATargetMajorInd',\n",
    "                                            'TR.MnATargetMajorIndGrp',\n",
    "                                            'TR.MnATargetHiTech(Concat=\"|\")',\n",
    "                                            'TR.MnAAcquirorUltParentPriHiTech',\n",
    "                                            'TR.MnAAcquirorHiTechGroup(Concat=\"|\")',\n",
    "                                            'TR.MnATargetHiTechGroup(Concat=\"|\")',\n",
    "                                            'TR.MnAWithdrawnDate',\n",
    "                                            'TR.MnADateUnconditional',\n",
    "                                            'TR.MnAOrigAnnDate',\n",
    "                                            'TR.MnAPercentCash',\n",
    "                                            'TR.MnADealCurrency',\n",
    "                                            'TR.MnAEarnoutDesc']) \n",
    "\n",
    "            print(mnas.shape)\n",
    "            mnas.columns = [col[3:].lower() for col in mnas.columns]\n",
    "\n",
    "            master_df = pd.concat([master_df, mnas], ignore_index=True)\n",
    "            print(f'Master shape: {master_df.shape}')\n",
    "\n",
    "            j += 1\n",
    "            success = True \n",
    "\n",
    "                \n",
    "            # Process some code every N iterations\n",
    "            if j % N == 0:\n",
    "                print(f\"Appending chunk to BQ\")\n",
    "                # Load the DataFrame into BigQuery\n",
    "                load_job = client.load_table_from_dataframe(master_df, table_ref, job_config=job_config)\n",
    "                # Wait for the load job to complete\n",
    "                load_job.result()\n",
    "                print(\"Data appended successfully\")\n",
    "                \n",
    "                # Reinitialize master_df to not store duplicate info next time this runs\n",
    "                master_df = pd.DataFrame()\n",
    "                j = 1\n",
    "        \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}. Retrying for the range {start} to {end}...\")\n",
    "            \n",
    "print(\"Uploading data to BQ...\")\n",
    "\n",
    "\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
