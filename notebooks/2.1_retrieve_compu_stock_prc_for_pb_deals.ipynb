{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace109cd-6bbc-463e-8ba3-fcde478f706d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a86b8114-3001-409f-aa3e-d3949f544c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: wrds in /opt/conda/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: numpy<1.27,>=1.26 in /opt/conda/lib/python3.10/site-packages (from wrds) (1.26.4)\n",
      "Requirement already satisfied: packaging<23.3 in /opt/conda/lib/python3.10/site-packages (from wrds) (23.2)\n",
      "Requirement already satisfied: pandas<2.3,>=2.2 in /opt/conda/lib/python3.10/site-packages (from wrds) (2.2.2)\n",
      "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /opt/conda/lib/python3.10/site-packages (from wrds) (2.9.9)\n",
      "Requirement already satisfied: scipy<1.13,>=1.12 in /opt/conda/lib/python3.10/site-packages (from wrds) (1.12.0)\n",
      "Requirement already satisfied: sqlalchemy<2.1,>=2 in /opt/conda/lib/python3.10/site-packages (from wrds) (2.0.29)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3,>=2.2->wrds) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3,>=2.2->wrds) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3,>=2.2->wrds) (2024.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<2.1,>=2->wrds) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<2.1,>=2->wrds) (3.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->wrds) (1.16.0)\n",
      "/home/jupyter\n",
      "{\n",
      "  \"shell_port\": 34039,\n",
      "  \"iopub_port\": 40133,\n",
      "  \"stdin_port\": 33747,\n",
      "  \"control_port\": 35377,\n",
      "  \"hb_port\": 42747,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"2d2e83e1-b9f9547dd7ec7c39d41bda49\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"conda-root-py\",\n",
      "  \"jupyter_session\": \"/home/jupyter/starfire/notebooks/data1.2_compu_stock_prices.ipynb\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-69aec95d-4172-41ca-adcf-f516dfdfecd4.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "!pip install openpyxl ## read excel files\n",
    "!pip install wrds\n",
    "import wrds\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "os.chdir('/home/jupyter')\n",
    "!pwd\n",
    "# # %cd \n",
    "# !pwd\n",
    "# (base) jupyter@starfire-1:~$ pip install jupyter-console\n",
    "# (base) jupyter@starfire-1:~$ !jupyter console --existing\n",
    "%connect_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa83672e-3763-4a7b-8326-abb6ddfc5542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      " Establishing WRDS connection:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your WRDS username [jupyter]: rogermasclans\n",
      "Enter your password: ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRDS recommends setting up a .pgpass file.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Create .pgpass file now [y/n]?:  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created .pgpass file successfully.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('----------------\\n Establishing WRDS connection:')\n",
    "# establish connection\n",
    "conn = wrds.Connection()\n",
    "\n",
    "# crsp_list = conn.list_tables(library='crsp')\n",
    "# crsp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723288b1-9d85-491b-940c-75aebc2c85c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f21680-b4b5-4e6a-b147-935ee8626b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading pitchbook data... \n",
      "\n",
      "Index(['targetid', 'mna_dealid', 'mna_dealsize', 'mna_anndate', 'mna_dealdate',\n",
      "       'mna_investorid', 'mna_investorname', 'mna_investorcikcode',\n",
      "       'mna_investorticker', 'mna_investorexchange', 'mna_investorparent',\n",
      "       'mna_investorctry', 'mna_eventdate'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>targetid</th>\n",
       "      <th>mna_dealid</th>\n",
       "      <th>mna_dealsize</th>\n",
       "      <th>mna_anndate</th>\n",
       "      <th>mna_dealdate</th>\n",
       "      <th>mna_investorid</th>\n",
       "      <th>mna_investorname</th>\n",
       "      <th>mna_investorcikcode</th>\n",
       "      <th>mna_investorticker</th>\n",
       "      <th>mna_investorexchange</th>\n",
       "      <th>mna_investorparent</th>\n",
       "      <th>mna_investorctry</th>\n",
       "      <th>mna_eventdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52298-56</td>\n",
       "      <td>46282-96T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>108237-43</td>\n",
       "      <td>AVL List</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Robert Bosch Engineering and Business Solutions</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2015-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58110-13</td>\n",
       "      <td>79999-39T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>169050-07</td>\n",
       "      <td>Harbour BioMed</td>\n",
       "      <td>None</td>\n",
       "      <td>02142</td>\n",
       "      <td>HKG</td>\n",
       "      <td>None</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>2016-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93819-79</td>\n",
       "      <td>248895-91T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>495749-98</td>\n",
       "      <td>WasteCo Holdings NZ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>2022-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>416586-16</td>\n",
       "      <td>136837-54T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>185763-25</td>\n",
       "      <td>Binance</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Cayman Islands</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>494440-39</td>\n",
       "      <td>191709-55T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>176590-99</td>\n",
       "      <td>Sheypoor</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Iran</td>\n",
       "      <td>2019-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47055</th>\n",
       "      <td>501471-10</td>\n",
       "      <td>224763-22T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>12465-46</td>\n",
       "      <td>Saga Group</td>\n",
       "      <td>None</td>\n",
       "      <td>SAGA</td>\n",
       "      <td>LON</td>\n",
       "      <td>None</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2023-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47056</th>\n",
       "      <td>140341-69</td>\n",
       "      <td>61839-37T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-07-25</td>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>531384-22</td>\n",
       "      <td>Nottingham College</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2015-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47057</th>\n",
       "      <td>146547-91</td>\n",
       "      <td>186749-29T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>118066-78</td>\n",
       "      <td>MyTutor</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2022-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47058</th>\n",
       "      <td>63654-94</td>\n",
       "      <td>34437-43T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>63667-81</td>\n",
       "      <td>Regenerys</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2012-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47059</th>\n",
       "      <td>471123-46</td>\n",
       "      <td>225119-26T</td>\n",
       "      <td>5.988034</td>\n",
       "      <td>2023-05-29</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>462731-32</td>\n",
       "      <td>Team (UK)</td>\n",
       "      <td>None</td>\n",
       "      <td>TEAM</td>\n",
       "      <td>LON</td>\n",
       "      <td>None</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2023-05-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47060 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        targetid  mna_dealid  mna_dealsize mna_anndate mna_dealdate  \\\n",
       "0       52298-56   46282-96T           NaN         NaN   2015-02-18   \n",
       "1       58110-13   79999-39T           NaN         NaN   2016-12-19   \n",
       "2       93819-79  248895-91T           NaN         NaN   2022-12-05   \n",
       "3      416586-16  136837-54T           NaN         NaN   2020-05-20   \n",
       "4      494440-39  191709-55T           NaN  2019-01-02   2019-01-02   \n",
       "...          ...         ...           ...         ...          ...   \n",
       "47055  501471-10  224763-22T           NaN         NaN   2023-02-27   \n",
       "47056  140341-69   61839-37T           NaN  2015-07-25   2017-06-08   \n",
       "47057  146547-91  186749-29T           NaN         NaN   2022-01-17   \n",
       "47058   63654-94   34437-43T           NaN         NaN   2012-12-18   \n",
       "47059  471123-46  225119-26T      5.988034  2023-05-29   2023-06-01   \n",
       "\n",
       "      mna_investorid     mna_investorname mna_investorcikcode  \\\n",
       "0          108237-43             AVL List                None   \n",
       "1          169050-07       Harbour BioMed                None   \n",
       "2          495749-98  WasteCo Holdings NZ                None   \n",
       "3          185763-25              Binance                None   \n",
       "4          176590-99             Sheypoor                None   \n",
       "...              ...                  ...                 ...   \n",
       "47055       12465-46           Saga Group                None   \n",
       "47056      531384-22   Nottingham College                None   \n",
       "47057      118066-78              MyTutor                None   \n",
       "47058       63667-81            Regenerys                None   \n",
       "47059      462731-32            Team (UK)                None   \n",
       "\n",
       "      mna_investorticker mna_investorexchange  \\\n",
       "0                   None                 None   \n",
       "1                  02142                  HKG   \n",
       "2                   None                 None   \n",
       "3                   None                 None   \n",
       "4                   None                 None   \n",
       "...                  ...                  ...   \n",
       "47055               SAGA                  LON   \n",
       "47056               None                 None   \n",
       "47057               None                 None   \n",
       "47058               None                 None   \n",
       "47059               TEAM                  LON   \n",
       "\n",
       "                                    mna_investorparent mna_investorctry  \\\n",
       "0      Robert Bosch Engineering and Business Solutions          Austria   \n",
       "1                                                 None        Hong Kong   \n",
       "2                                                 None      New Zealand   \n",
       "3                                                 None   Cayman Islands   \n",
       "4                                                 None             Iran   \n",
       "...                                                ...              ...   \n",
       "47055                                             None   United Kingdom   \n",
       "47056                                             None   United Kingdom   \n",
       "47057                                             None   United Kingdom   \n",
       "47058                                             None   United Kingdom   \n",
       "47059                                             None   United Kingdom   \n",
       "\n",
       "      mna_eventdate  \n",
       "0        2015-02-18  \n",
       "1        2016-12-19  \n",
       "2        2022-12-05  \n",
       "3        2020-05-20  \n",
       "4        2019-01-02  \n",
       "...             ...  \n",
       "47055    2023-02-27  \n",
       "47056    2015-07-25  \n",
       "47057    2022-01-17  \n",
       "47058    2012-12-18  \n",
       "47059    2023-05-29  \n",
       "\n",
       "[47060 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Download data from BQ, Startups with MnA deals\n",
    "\n",
    "print('downloading pitchbook data... \\n')\n",
    "\n",
    "# Define project on BQ\n",
    "project_id = \"starfire-410116\"\n",
    "\n",
    "# Authenticate to Google Cloud\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Set allow_large_results to Truepoti\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "job_config.allow_large_results = True\n",
    "\n",
    "query_txt = \"\"\"\n",
    "SELECT \n",
    "    targetid, mna_dealid, mna_dealsize, \n",
    "    mna_anndate, mna_dealdate, \n",
    "    mna_investorid, mna_investorname,\n",
    "    mna_investorcikcode, mna_investorticker,\n",
    "    mna_investorexchange, mna_investorparent, mna_investorctry,\n",
    "FROM `starfire-410116.derived.all_sups` \n",
    "WHERE mna_dealid IS NOT NULL\n",
    "\"\"\" \n",
    "\n",
    "# Construct the SQL query to fetch data from BigQuery\n",
    "query = f'{query_txt}'\n",
    "\n",
    "# Fetch data from BigQuery\n",
    "query_job = client.query(query, job_config=job_config)\n",
    "results = query_job.result()  # Waits for the query to complete\n",
    "\n",
    "# Convert the result to a pandas DataFrame\n",
    "df = results.to_dataframe()\n",
    "\n",
    "\n",
    "## Format dates\n",
    "df['mna_anndate'] = [ts.strftime('%Y-%m-%d') if pd.notna(ts) else np.nan for ts in df['mna_anndate']]\n",
    "df['mna_dealdate'] = [ts.strftime('%Y-%m-%d') if pd.notna(ts) else np.nan for ts in df['mna_dealdate']]\n",
    "df['mna_eventdate'] = df['mna_anndate'].combine_first(df['mna_dealdate'])\n",
    "\n",
    "#standardize cik codes to 10 digits with 00\n",
    "df['mna_investorcikcode'] = [item.strip().rjust(10, '0') if isinstance(item, str) else item for item in df['mna_investorcikcode']]\n",
    "\n",
    "print(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08f1e74f-7ce3-4288-9824-5988cabf9c74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>targetid</th>\n",
       "      <th>mna_dealid</th>\n",
       "      <th>mna_dealsize</th>\n",
       "      <th>mna_anndate</th>\n",
       "      <th>mna_dealdate</th>\n",
       "      <th>mna_investorid</th>\n",
       "      <th>mna_investorname</th>\n",
       "      <th>mna_investorcikcode</th>\n",
       "      <th>mna_investorticker</th>\n",
       "      <th>mna_investorexchange</th>\n",
       "      <th>mna_investorparent</th>\n",
       "      <th>mna_investorctry</th>\n",
       "      <th>mna_eventdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52298-56</td>\n",
       "      <td>46282-96T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>108237-43</td>\n",
       "      <td>AVL List</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Robert Bosch Engineering and Business Solutions</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2015-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58110-13</td>\n",
       "      <td>79999-39T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>169050-07</td>\n",
       "      <td>Harbour BioMed</td>\n",
       "      <td>None</td>\n",
       "      <td>02142</td>\n",
       "      <td>HKG</td>\n",
       "      <td>None</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>2016-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93819-79</td>\n",
       "      <td>248895-91T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>495749-98</td>\n",
       "      <td>WasteCo Holdings NZ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>2022-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>416586-16</td>\n",
       "      <td>136837-54T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>185763-25</td>\n",
       "      <td>Binance</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Cayman Islands</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>494440-39</td>\n",
       "      <td>191709-55T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>176590-99</td>\n",
       "      <td>Sheypoor</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Iran</td>\n",
       "      <td>2019-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48351</th>\n",
       "      <td>501471-10</td>\n",
       "      <td>224763-22T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>12465-46</td>\n",
       "      <td>Saga Group</td>\n",
       "      <td>None</td>\n",
       "      <td>SAGA</td>\n",
       "      <td>LON</td>\n",
       "      <td>None</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2023-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48352</th>\n",
       "      <td>140341-69</td>\n",
       "      <td>61839-37T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-07-25</td>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>531384-22</td>\n",
       "      <td>Nottingham College</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2015-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48353</th>\n",
       "      <td>146547-91</td>\n",
       "      <td>186749-29T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>118066-78</td>\n",
       "      <td>MyTutor</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2022-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48354</th>\n",
       "      <td>63654-94</td>\n",
       "      <td>34437-43T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>63667-81</td>\n",
       "      <td>Regenerys</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2012-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48355</th>\n",
       "      <td>471123-46</td>\n",
       "      <td>225119-26T</td>\n",
       "      <td>5.988034</td>\n",
       "      <td>2023-05-29</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>462731-32</td>\n",
       "      <td>Team (UK)</td>\n",
       "      <td>None</td>\n",
       "      <td>TEAM</td>\n",
       "      <td>LON</td>\n",
       "      <td>None</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2023-05-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48356 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        targetid  mna_dealid  mna_dealsize mna_anndate mna_dealdate  \\\n",
       "0       52298-56   46282-96T           NaN         NaN   2015-02-18   \n",
       "1       58110-13   79999-39T           NaN         NaN   2016-12-19   \n",
       "2       93819-79  248895-91T           NaN         NaN   2022-12-05   \n",
       "3      416586-16  136837-54T           NaN         NaN   2020-05-20   \n",
       "4      494440-39  191709-55T           NaN  2019-01-02   2019-01-02   \n",
       "...          ...         ...           ...         ...          ...   \n",
       "48351  501471-10  224763-22T           NaN         NaN   2023-02-27   \n",
       "48352  140341-69   61839-37T           NaN  2015-07-25   2017-06-08   \n",
       "48353  146547-91  186749-29T           NaN         NaN   2022-01-17   \n",
       "48354   63654-94   34437-43T           NaN         NaN   2012-12-18   \n",
       "48355  471123-46  225119-26T      5.988034  2023-05-29   2023-06-01   \n",
       "\n",
       "      mna_investorid     mna_investorname mna_investorcikcode  \\\n",
       "0          108237-43             AVL List                None   \n",
       "1          169050-07       Harbour BioMed                None   \n",
       "2          495749-98  WasteCo Holdings NZ                None   \n",
       "3          185763-25              Binance                None   \n",
       "4          176590-99             Sheypoor                None   \n",
       "...              ...                  ...                 ...   \n",
       "48351       12465-46           Saga Group                None   \n",
       "48352      531384-22   Nottingham College                None   \n",
       "48353      118066-78              MyTutor                None   \n",
       "48354       63667-81            Regenerys                None   \n",
       "48355      462731-32            Team (UK)                None   \n",
       "\n",
       "      mna_investorticker mna_investorexchange  \\\n",
       "0                   None                 None   \n",
       "1                  02142                  HKG   \n",
       "2                   None                 None   \n",
       "3                   None                 None   \n",
       "4                   None                 None   \n",
       "...                  ...                  ...   \n",
       "48351               SAGA                  LON   \n",
       "48352               None                 None   \n",
       "48353               None                 None   \n",
       "48354               None                 None   \n",
       "48355               TEAM                  LON   \n",
       "\n",
       "                                    mna_investorparent mna_investorctry  \\\n",
       "0      Robert Bosch Engineering and Business Solutions          Austria   \n",
       "1                                                 None        Hong Kong   \n",
       "2                                                 None      New Zealand   \n",
       "3                                                 None   Cayman Islands   \n",
       "4                                                 None             Iran   \n",
       "...                                                ...              ...   \n",
       "48351                                             None   United Kingdom   \n",
       "48352                                             None   United Kingdom   \n",
       "48353                                             None   United Kingdom   \n",
       "48354                                             None   United Kingdom   \n",
       "48355                                             None   United Kingdom   \n",
       "\n",
       "      mna_eventdate  \n",
       "0        2015-02-18  \n",
       "1        2016-12-19  \n",
       "2        2022-12-05  \n",
       "3        2020-05-20  \n",
       "4        2019-01-02  \n",
       "...             ...  \n",
       "48351    2023-02-27  \n",
       "48352    2015-07-25  \n",
       "48353    2022-01-17  \n",
       "48354    2012-12-18  \n",
       "48355    2023-05-29  \n",
       "\n",
       "[48356 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mna_investorcikcode'] = df['mna_investorcikcode'].str.split(',') \n",
    "df = df.explode('mna_investorcikcode').reset_index(drop=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f566924-ca9c-4945-a2cc-47334fd28ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique targetid: 43644\n",
      "Unique mna_dealid: 46446\n",
      "Unique mna_investor: 26499\n",
      "Unique mna_dealid with unique targetid: 43644\n",
      "Unique mna_dealid with mna_eventdate non null: 45335\n",
      "Unique mna_dealid with mna_anndate non null: 45335\n",
      "Unique mna_dealid with mna_dealdate non null: 8362\n",
      "Unique mna_dealid with mna_dealsize non null: 15304\n",
      "Unique mna_dealid with mna_dealsize non null and mna_eventdate non null: 15269\n",
      "Unique mna_dealid with mna_investorcikcode not null: 20309\n",
      "Unique mna_dealid with mna_investorticker not null: 14869\n",
      "Unique mna_dealid with mna_dealsize non null and mna_eventdate non null and mna_investorcikcode not null: 9660\n",
      "Unique mna_dealid with mna_dealsize non null and mna_eventdate non null and mna_investorticker not null: 8271\n",
      "Unique mna_investorcikcode: 8279\n",
      "Unique mna_investorticker: 5072\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics\n",
    "un_targetid = df['targetid'].nunique()\n",
    "un_mna_dealid = df['mna_dealid'].nunique()\n",
    "un_mna_investors = df['mna_investorid'].nunique()\n",
    "# un_mna_dealid_eventdate_non_null = df[df['mna_eventdate'].notnull()]['mna_dealid'].nunique()\n",
    "un_mna_dealid_eventdate_non_null = df[df['mna_eventdate'].notna()]['mna_dealid'].nunique()\n",
    "un_mna_dealid_anndate_non_null = df[df['mna_eventdate'].notna()]['mna_dealid'].nunique()\n",
    "un_mna_dealid_dealdate_non_null = df[df['mna_anndate'].notna()]['mna_dealid'].nunique()\n",
    "un_mna_dealid_dealsize_non_null = df[df['mna_dealsize'].notnull()]['mna_dealid'].nunique()\n",
    "un_mna_dealid_dealsize_eventdate_non_null = df[df['mna_dealsize'].notnull() & df['mna_eventdate'].notna()]['mna_dealid'].nunique()\n",
    "un_mna_dealid_investorcikcode_non_null = df[df['mna_investorcikcode'].notnull()]['mna_dealid'].nunique()\n",
    "un_mna_dealid_investorticker_non_null = df[df['mna_investorticker'].notnull()]['mna_dealid'].nunique()\n",
    "un_mna_dealid_dealsize_eventdate_investorcikcode_non_null = df[df['mna_dealsize'].notnull() & df['mna_eventdate'].notna() & df['mna_investorcikcode'].notnull()]['mna_dealid'].nunique()\n",
    "un_mna_dealid_dealsize_eventdate_investorticker_non_null = df[df['mna_dealsize'].notnull() & df['mna_eventdate'].notna() & df['mna_investorticker'].notnull()]['mna_dealid'].nunique()\n",
    "un_mna_investorcikcode = df['mna_investorcikcode'].nunique()\n",
    "un_mna_investorticker = df['mna_investorticker'].nunique()\n",
    "\n",
    "# Print the results\n",
    "print(f'Unique targetid: {un_targetid}')\n",
    "print(f'Unique mna_dealid: {un_mna_dealid}')\n",
    "print(f'Unique mna_investor: {un_mna_investors}')\n",
    "print(f'Unique mna_dealid with unique targetid:', df.groupby('targetid')['mna_dealid'].nunique().count())\n",
    "print(f'Unique mna_dealid with mna_eventdate non null: {un_mna_dealid_eventdate_non_null}')\n",
    "print(f'Unique mna_dealid with mna_anndate non null: {un_mna_dealid_anndate_non_null}')\n",
    "print(f'Unique mna_dealid with mna_dealdate non null: {un_mna_dealid_dealdate_non_null}')\n",
    "print(f'Unique mna_dealid with mna_dealsize non null: {un_mna_dealid_dealsize_non_null}')\n",
    "print(f'Unique mna_dealid with mna_dealsize non null and mna_eventdate non null: {un_mna_dealid_dealsize_eventdate_non_null}')\n",
    "print(f'Unique mna_dealid with mna_investorcikcode not null: {un_mna_dealid_investorcikcode_non_null}')\n",
    "print(f'Unique mna_dealid with mna_investorticker not null: {un_mna_dealid_investorticker_non_null}')\n",
    "print(f'Unique mna_dealid with mna_dealsize non null and mna_eventdate non null and mna_investorcikcode not null: {un_mna_dealid_dealsize_eventdate_investorcikcode_non_null}')\n",
    "print(f'Unique mna_dealid with mna_dealsize non null and mna_eventdate non null and mna_investorticker not null: {un_mna_dealid_dealsize_eventdate_investorticker_non_null}')\n",
    "print(f'Unique mna_investorcikcode: {un_mna_investorcikcode}')\n",
    "print(f'Unique mna_investorticker: {un_mna_investorticker}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ecc3c1-00b8-4d17-8f86-a9de39ccce2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download stock prices on event date for PB deals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe463b-9e71-4834-aa93-b1103d3a6374",
   "metadata": {},
   "source": [
    "### Compustat North America\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c606991-547f-498d-866f-319ece907dda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length unique ciks: 8279\n",
      "\n",
      "Global: \n",
      "      gvkey         cik                          conm\n",
      "0    001661  0001163739         NABORS INDUSTRIES LTD\n",
      "1    001932  0001303523      BRITISH AMER TOBACCO PLC\n",
      "2    002338  0000013522                     REXAM PLC\n",
      "3    002410  0000313807                        BP PLC\n",
      "4    002411  0000756620                  BT GROUP PLC\n",
      "..      ...         ...                           ...\n",
      "590  345606  0001978867                   CADELER A/S\n",
      "591  348615  0001901279                     NAYAX LTD\n",
      "592  348892  0001828098         STEAKHOLDER FOODS LTD\n",
      "593  351038  0001671502     QUOIN PHARMACEUTICALS LTD\n",
      "594  356128  0001985487  JOINT STOCK COMPANY KASPI KZ\n",
      "\n",
      "[595 rows x 3 columns]\n",
      "\n",
      "North America: \n",
      "       gvkey         cik                          conm\n",
      "0     001004  0000001750                      AAR CORP\n",
      "1     001013  0000061478    ADC TELECOMMUNICATIONS INC\n",
      "2     001056  0000002601                  AEROFLEX INC\n",
      "3     001072  0000859163                      AVX CORP\n",
      "4     001078  0000001800           ABBOTT LABORATORIES\n",
      "...      ...         ...                           ...\n",
      "4286  348892  0001828098         STEAKHOLDER FOODS LTD\n",
      "4287  349530  0001372183     NEXTPLAY TECHNOLOGIES INC\n",
      "4288  349972  0001857044     INDAPTUS THERAPEUTICS INC\n",
      "4289  351038  0001671502     QUOIN PHARMACEUTICALS LTD\n",
      "4290  356128  0001985487  JOINT STOCK COMPANY KASPI KZ\n",
      "\n",
      "[4291 rows x 3 columns]\n",
      "\n",
      "All: \n",
      "       gvkey         cik                          conm\n",
      "0     001004  0000001750                      AAR CORP\n",
      "1     001013  0000061478    ADC TELECOMMUNICATIONS INC\n",
      "2     001056  0000002601                  AEROFLEX INC\n",
      "3     001072  0000859163                      AVX CORP\n",
      "4     001078  0000001800           ABBOTT LABORATORIES\n",
      "...      ...         ...                           ...\n",
      "4881  345606  0001978867                   CADELER A/S\n",
      "4882  348615  0001901279                     NAYAX LTD\n",
      "4883  348892  0001828098         STEAKHOLDER FOODS LTD\n",
      "4884  351038  0001671502     QUOIN PHARMACEUTICALS LTD\n",
      "4885  356128  0001985487  JOINT STOCK COMPANY KASPI KZ\n",
      "\n",
      "[4886 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "## Check cikcode present in compustat dataset. North America v Global\n",
    "\n",
    "unique_ciks = df['mna_investorcikcode'].dropna().astype(str).unique().tolist()\n",
    "unique_ciks = [item.strip().rjust(10, '0') for item in unique_ciks]\n",
    "print(f'\\nLength unique ciks: {len(unique_ciks)}')\n",
    "\n",
    "# Create single string of type 'yyy', 'yyy', ...  to pass to SQL query\n",
    "unique_ciks = ', '.join([f\"'{item}'\" for item in unique_ciks])\n",
    "\n",
    "# Get list of cik codes in Global Compustat stock price dataset\n",
    "stock_ciks_glb = conn.raw_sql(\n",
    "    f\"\"\"\n",
    "        SELECT\n",
    "            gvkey, cik, conm\n",
    "        FROM comp_global_daily.g_company\n",
    "        where cik IN ({unique_ciks})\n",
    "    \"\"\"\n",
    ")\n",
    "print(f'\\nGlobal: \\n{stock_ciks_glb}')\n",
    "\n",
    "\n",
    "# Get list of cik codes in North America Compustat stock price dataset\n",
    "stock_ciks_na = conn.raw_sql(\n",
    "    f\"\"\"\n",
    "        SELECT\n",
    "            gvkey, cik, conm\n",
    "        FROM comp_na_daily_all.company\n",
    "        where cik IN ({unique_ciks})\n",
    "    \"\"\"\n",
    ")\n",
    "print(f'\\nNorth America: \\n{stock_ciks_na}')\n",
    "\n",
    "\n",
    "# Concatenate lists to get total unique number of ciks\n",
    "stock_ciks_all = pd.concat([stock_ciks_na,stock_ciks_glb],axis=0 )\n",
    "stock_ciks_all = stock_ciks_all.reset_index(drop=True)\n",
    "print(f'\\nAll: \\n{stock_ciks_all}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b06bf71-c61a-4130-b67d-2b627df959fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4293\n",
      "4293\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>cik</th>\n",
       "      <th>conm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>001661</td>\n",
       "      <td>0001163739</td>\n",
       "      <td>NABORS INDUSTRIES LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>001932</td>\n",
       "      <td>0001303523</td>\n",
       "      <td>BRITISH AMER TOBACCO PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>002338</td>\n",
       "      <td>0000013522</td>\n",
       "      <td>REXAM PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>002410</td>\n",
       "      <td>0000313807</td>\n",
       "      <td>BP PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>002411</td>\n",
       "      <td>0000756620</td>\n",
       "      <td>BT GROUP PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>345606</td>\n",
       "      <td>0001978867</td>\n",
       "      <td>CADELER A/S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>348615</td>\n",
       "      <td>0001901279</td>\n",
       "      <td>NAYAX LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>348892</td>\n",
       "      <td>0001828098</td>\n",
       "      <td>STEAKHOLDER FOODS LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>351038</td>\n",
       "      <td>0001671502</td>\n",
       "      <td>QUOIN PHARMACEUTICALS LTD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>356128</td>\n",
       "      <td>0001985487</td>\n",
       "      <td>JOINT STOCK COMPANY KASPI KZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gvkey         cik                          conm\n",
       "31    001661  0001163739         NABORS INDUSTRIES LTD\n",
       "49    001932  0001303523      BRITISH AMER TOBACCO PLC\n",
       "72    002338  0000013522                     REXAM PLC\n",
       "76    002410  0000313807                        BP PLC\n",
       "77    002411  0000756620                  BT GROUP PLC\n",
       "...      ...         ...                           ...\n",
       "4280  345606  0001978867                   CADELER A/S\n",
       "4285  348615  0001901279                     NAYAX LTD\n",
       "4286  348892  0001828098         STEAKHOLDER FOODS LTD\n",
       "4289  351038  0001671502     QUOIN PHARMACEUTICALS LTD\n",
       "4290  356128  0001985487  JOINT STOCK COMPANY KASPI KZ\n",
       "\n",
       "[593 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many deals with CIK with stock market data as per last cell\n",
    "print(len(stock_ciks_all['gvkey'].unique()))\n",
    "print(len(stock_ciks_all['cik'].unique()))\n",
    "\n",
    "matching_rows = df[df['mna_investorcikcode'].isin(stock_ciks_all['cik'])]\n",
    "matching_rows\n",
    "\n",
    "\n",
    "## Looks like NA includes all but 2 ciks in Global. Why then the diff datasets?\n",
    "matching_rows = stock_ciks_na[stock_ciks_na['cik'].isin(stock_ciks_glb['cik'])]\n",
    "matching_rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4289f83f-32eb-47de-9621-70b514a9eb33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>conm</th>\n",
       "      <th>cusip</th>\n",
       "      <th>exchg</th>\n",
       "      <th>fic</th>\n",
       "      <th>tpci</th>\n",
       "      <th>iid</th>\n",
       "      <th>datadate</th>\n",
       "      <th>cik</th>\n",
       "      <th>prccd</th>\n",
       "      <th>prcstd</th>\n",
       "      <th>cshoc</th>\n",
       "      <th>cshtrd</th>\n",
       "      <th>curcdd</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>mna_investorcikcode</th>\n",
       "      <th>mna_eventdate</th>\n",
       "      <th>mna_dealid</th>\n",
       "      <th>loop_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gvkey, conm, cusip, exchg, fic, tpci, iid, datadate, cik, prccd, prcstd, cshoc, cshtrd, curcdd, Start, End, mna_investorcikcode, mna_eventdate, mna_dealid, loop_counter]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cik = '0000899115'\n",
    "start_date = '2009-10-14'\n",
    "end_date = '2009-10-20'\n",
    "\n",
    "stock_ciks_na = conn.raw_sql(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        gvkey, conm, cusip,\n",
    "        exchg, fic, tpci, iid,\n",
    "        datadate, cik, prccd, prcstd, cshoc, cshtrd, curcdd\n",
    "    FROM comp_na_daily_all.secd\n",
    "    WHERE \n",
    "        cik = '0000899115'\n",
    "limit 10\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "stock_ciks_na = pd.DataFrame(stock_ciks_na)\n",
    "\n",
    "# Add additional columns to the result (start, end, MnAAnnDate, RIC)\n",
    "stock_ciks_na['Start'] = start_date\n",
    "stock_ciks_na['End'] = end_date\n",
    "stock_ciks_na['mna_investorcikcode'] = cikcode\n",
    "stock_ciks_na['mna_eventdate'] = mna_eventdate\n",
    "stock_ciks_na['mna_dealid'] = mnapbdealid\n",
    "stock_ciks_na['loop_counter'] = counter\n",
    "# stock_ciks_na = stock_ciks_na.groupby('mna_dealid').apply(calculate_lag).reset_index(drop=True)\n",
    "\n",
    "stock_ciks_na\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d6cb00d-a890-421a-8007-051637766fc2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop starts...\n",
      "-----0. Downloading data for 0001001290...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----1. Downloading data for 0001496780...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----2. Downloading data for 0001001290...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----3. Downloading data for 0001875609...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----4. Downloading data for 0001099590...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----5. Downloading data for 0001474968...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----6. Downloading data for 0001474968...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----7. Downloading data for 0001525028...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----8. Downloading data for 0001550903...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----9. Downloading data for 0001525290...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----10. Downloading data for 0001709135...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----11. Downloading data for 0001804469...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----12. Downloading data for 0001697818...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----13. Downloading data for 0001874074...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----14. Downloading data for 0001804469...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----15. Downloading data for 0001550903...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----16. Downloading data for 0001474968...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----17. Downloading data for 0001746309...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----18. Downloading data for 0001462418...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----19. Downloading data for 0001163417...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----20. Downloading data for 0001029974...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----21. Downloading data for 0001530256...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----22. Downloading data for 0001533475...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----23. Downloading data for 0001778485...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----24. Downloading data for 0001243429...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----25. Downloading data for 0001576874...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----26. Downloading data for 1750718...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----27. Downloading data for  1719489...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----28. Downloading data for 0001674928...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----29. Downloading data for 0000948642...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----30. Downloading data for 0000948642...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----31. Downloading data for 0001258150...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----32. Downloading data for 0001876386...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----33. Downloading data for 0001701103...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----34. Downloading data for 0001701103...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----35. Downloading data for 0001701103...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----36. Downloading data for 0001986191...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----37. Downloading data for 0001916077...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----38. Downloading data for 0001097636...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----39. Downloading data for 0001581987...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----40. Downloading data for 0001875609...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----41. Downloading data for 0001099590...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----42. Downloading data for 0001704527...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----43. Downloading data for 0001755887...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----44. Downloading data for 0001811663...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----45. Downloading data for 0001703141...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----46. Downloading data for 0001099590...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----47. Downloading data for 0001099590...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----48. Downloading data for 0001799344...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----49. Downloading data for 0001957146...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----50. Downloading data for 0001693234...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----51. Downloading data for 0001129137...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----52. Downloading data for 0001693234...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----53. Downloading data for 0001703141...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----54. Downloading data for 0000353278...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----55. Downloading data for 0001674988...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----56. Downloading data for 0001445168...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----57. Downloading data for 1102104...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----58. Downloading data for  1360869...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----59. Downloading data for 0001955494...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----60. Downloading data for 0001436673...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----61. Downloading data for 0001537133...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----62. Downloading data for 0000924613...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----63. Downloading data for 0001062750...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----64. Downloading data for 0001140124...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----65. Downloading data for 0001528903...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----66. Downloading data for 0001445168...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----67. Downloading data for 0001436514...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----68. Downloading data for 0001469059...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----69. Downloading data for 0001848739...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----70. Downloading data for 0001513845...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----71. Downloading data for 0001668717...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----72. Downloading data for 0001701103...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----73. Downloading data for 0001436513...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----74. Downloading data for 0001163417...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----75. Downloading data for 0001557860...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----76. Downloading data for 0000924613...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----77. Downloading data for 0001916077...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----78. Downloading data for 0001243429...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----79. Downloading data for 0001128749...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----80. Downloading data for 0001701103...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----81. Downloading data for 0001701103...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----82. Downloading data for 0001916077...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----83. Downloading data for 0001435969...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----84. Downloading data for 0001528903...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----85. Downloading data for 0001668717...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----86. Downloading data for 0001513845...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----87. Downloading data for 0001129137...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----88. Downloading data for 0001673209...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----89. Downloading data for 0001571752...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----90. Downloading data for 0001673209...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----91. Downloading data for 0001693234...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----92. Downloading data for 0001875609...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----93. Downloading data for 0001822028...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----94. Downloading data for 0001742740...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----95. Downloading data for 0001822425...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----96. Downloading data for 0001163739...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----97. Downloading data for 0001436630...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----98. Downloading data for 0001330306...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----99. Downloading data for 0001163739...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----100. Downloading data for 0001096200...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----101. Downloading data for 0000924613...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----102. Downloading data for 0001099590...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----103. Downloading data for 0001532589...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----104. Downloading data for 0001454461...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----105. Downloading data for 0001513845...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----106. Downloading data for 0001822829...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----107. Downloading data for 1498315...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----108. Downloading data for  1474205...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----109. Downloading data for 0001513845...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----110. Downloading data for 0001561566...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----111. Downloading data for 0001523101...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----112. Downloading data for 0001523101...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----113. Downloading data for 0001115837...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----114. Downloading data for 0001523101...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----115. Downloading data for 0001513845...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----116. Downloading data for 0001513845...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----117. Downloading data for 0001561566...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----118. Downloading data for 0001523101...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----119. Downloading data for 0001523101...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----120. Downloading data for 0001513845...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----121. Downloading data for 0001523101...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----122. Downloading data for 0001523101...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----123. Downloading data for 0001523101...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----124. Downloading data for 0001561566...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----125. Downloading data for 0001115837...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----126. Downloading data for 0001513845...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----127. Downloading data for 0001115837...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----128. Downloading data for 0001580732...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----129. Downloading data for 0001580732...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----130. Downloading data for 0001436514...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----131. Downloading data for 0001538375...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----132. Downloading data for 0000924613...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----133. Downloading data for 0001580732...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----134. Downloading data for 0000801904...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----135. Downloading data for 0001172494...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----136. Downloading data for 0001876431...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----137. Downloading data for 0001033767...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----138. Downloading data for 0001046179...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----139. Downloading data for 0001033767...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----140. Downloading data for 0000924613...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----141. Downloading data for 0001526078...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----142. Downloading data for 0001589896...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----143. Downloading data for 0001570187...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----144. Downloading data for 0001436786...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----145. Downloading data for 0001436430...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----146. Downloading data for 1450238...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----147. Downloading data for  1450283...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----148. Downloading data for 0001604481...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----149. Downloading data for 0000930826...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----150. Downloading data for 0001131345...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----151. Downloading data for 0001290640...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----152. Downloading data for 0001437153...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----153. Downloading data for 0001437153...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----154. Downloading data for 0001653067...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----155. Downloading data for 0000353278...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----156. Downloading data for 0001436630...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----157. Downloading data for 0001307579...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----158. Downloading data for 0001978867...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----159. Downloading data for 0001380366...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----160. Downloading data for 0001206828...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----161. Downloading data for 0001821651...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----162. Downloading data for 0001436740...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----163. Downloading data for 0001436772...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----164. Downloading data for 0001988894...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----165. Downloading data for 0001436740...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----166. Downloading data for 0001436771...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----167. Downloading data for 0001436796...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----168. Downloading data for 0001722356...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----169. Downloading data for 0001916077...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----170. Downloading data for 0001436796...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----171. Downloading data for 0001436786...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----172. Downloading data for 0000924613...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----173. Downloading data for 0001632557...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----174. Downloading data for 0001436796...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----175. Downloading data for 0000899115...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----176. Downloading data for 0001579695...\n",
      "----------stock_prices_df Shape: (0, 20)\n",
      "-----177. Downloading data for 0000353278...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m end_date \u001b[38;5;241m=\u001b[39m (mna_eventdate \u001b[38;5;241m+\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m))\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-----\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcounter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Downloading data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcikcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m stock_ciks_na \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;43m    SELECT\u001b[39;49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;43m        gvkey, conm, cusip,\u001b[39;49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;43m        exchg, fic, tpci, iid,\u001b[39;49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;43m        datadate, cik, prccd, prcstd, cshoc, cshtrd, curcdd\u001b[39;49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;43m    FROM comp_na_daily_all.secd\u001b[39;49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;43m    WHERE \u001b[39;49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;43m        cik = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcikcode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;43m        AND \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstart_date\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m < datadate AND datadate < \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mend_date\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     77\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m stock_ciks_na \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(stock_ciks_na)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Add additional columns to the result (start, end, MnAAnnDate, RIC)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wrds/sql.py:566\u001b[0m, in \u001b[0;36mConnection.raw_sql\u001b[0;34m(self, sql, coerce_float, date_cols, index_col, params, chunksize, return_iter)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03mQueries the database using a raw SQL string.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m    2003-09-10  09:35:20.709000  N       AA       None     None  108100.0  28.200          N      00  1.929947e+15         C  None\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_iter \u001b[38;5;129;01mor\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/sql.py:1836\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   1780\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1781\u001b[0m     sql: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1788\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;124;03m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[1;32m   1792\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1834\u001b[0m \n\u001b[1;32m   1835\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1836\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1837\u001b[0m     columns \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m   1839\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/sql.py:1659\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   1657\u001b[0m args \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1783\u001b[0m, in \u001b[0;36mConnection.exec_driver_sql\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1778\u001b[0m execution_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execution_options\u001b[38;5;241m.\u001b[39mmerge_with(\n\u001b[1;32m   1779\u001b[0m     execution_options\n\u001b[1;32m   1780\u001b[0m )\n\u001b[1;32m   1782\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[0;32m-> 1783\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1850\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1990\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1990\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1991\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1992\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2360\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2358\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2359\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2360\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m   2361\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2362\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1971\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1969\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1971\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1972\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1973\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1976\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1977\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1978\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1982\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1983\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sqlalchemy/engine/default.py:919\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 919\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/encodings/utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[1;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop to get stock price for each cik\n",
    "## Create consecutive lags\n",
    "def calculate_lag(group):\n",
    "    # Find the index of the row where Date equals MnAAnnDate\n",
    "    matching_indices = group.index[group['datadate'] == group['mna_eventdate']].tolist()\n",
    "    \n",
    "    if matching_indices:\n",
    "        # Exact match found\n",
    "        baseline_index = matching_indices[0]\n",
    "    else:\n",
    "        # No exact match, find the first date after MnAAnnDate\n",
    "        after_mna_date = group[group['datadate'] > group['mna_eventdate'].iloc[0]]\n",
    "        if not after_mna_date.empty:\n",
    "            baseline_index = after_mna_date.index[0]\n",
    "        else:\n",
    "            # If no date is after MnAAnnDate, fallback to using the latest date\n",
    "            baseline_index = group.index[-1]\n",
    "    \n",
    "    # Calculate the lag by subtracting the baseline_index from the current index\n",
    "    group['lag'] = group.index - baseline_index\n",
    "    \n",
    "    return group\n",
    "\n",
    "\n",
    "project_id = \"starfire-410116\"\n",
    "dataset_id = \"derived\"\n",
    "table_id = \"compu_pb_stck_prc_v3\"\n",
    "\n",
    "\n",
    "# Construct a reference to the target table\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "# Configure the load job to append data to the existing table\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND\n",
    ")\n",
    "\n",
    "\n",
    "## Iterate over df_deals to get stock price data for days around acquisition\n",
    "\n",
    "# Suppress warnings -- reinstated at the end of the loop\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Ensure 'TR.MnAAnnDate' is in datetime format\n",
    "df['mna_eventdate'] = pd.to_datetime(df['mna_eventdate'])\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "stock_prices_df = pd.DataFrame()\n",
    "\n",
    "# Counter to track the number of lines processed\n",
    "counter = 0\n",
    "\n",
    "print(f\"Loop starts...\")\n",
    "\n",
    "for index, row in df[df['mna_investorcikcode'].notna()  & (df['mna_eventdate'].notna()) ].iterrows():\n",
    "\n",
    "    cikcode = row['mna_investorcikcode']\n",
    "    mna_eventdate = row['mna_eventdate']\n",
    "    mnapbdealid = row['mna_dealid']\n",
    "    \n",
    "    # Calculate start and end dates (mnaanndate - 7 days and mnaanndate + 7 days)\n",
    "    start_date = (mna_eventdate - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "    end_date = (mna_eventdate + timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "\n",
    "    print(f'-----{counter}. Downloading data for {cikcode}...')\n",
    "    stock_ciks_na = conn.raw_sql(\n",
    "        f\"\"\"\n",
    "        SELECT\n",
    "            gvkey, conm, cusip,\n",
    "            exchg, fic, tpci, iid,\n",
    "            datadate, cik, prccd, prcstd, cshoc, cshtrd, curcdd\n",
    "        FROM comp_na_daily_all.secd\n",
    "        WHERE \n",
    "            cik = '{cikcode}'\n",
    "            AND '{start_date}' < datadate AND datadate < '{end_date}'\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    stock_ciks_na = pd.DataFrame(stock_ciks_na)\n",
    "    \n",
    "    # Add additional columns to the result (start, end, MnAAnnDate, RIC)\n",
    "    stock_ciks_na['Start'] = start_date\n",
    "    stock_ciks_na['End'] = end_date\n",
    "    stock_ciks_na['mna_investorcikcode'] = cikcode\n",
    "    stock_ciks_na['mna_eventdate'] = mna_eventdate\n",
    "    stock_ciks_na['mna_dealid'] = mnapbdealid\n",
    "    stock_ciks_na['loop_counter'] = counter\n",
    "    stock_ciks_na = stock_ciks_na.groupby('mna_dealid').apply(calculate_lag).reset_index(drop=True)\n",
    "\n",
    "    # print(f'----------stock_ciks_na Shape: {stock_ciks_na.shape}')\n",
    "\n",
    "\n",
    "    # Convert to date format to later process lag functions\n",
    "    stock_ciks_na['datadate'] = pd.to_datetime(stock_ciks_na['datadate'], errors='coerce')\n",
    "    stock_ciks_na['Start'] = pd.to_datetime(stock_ciks_na['Start'], errors='coerce')\n",
    "    stock_ciks_na['End'] = pd.to_datetime(stock_ciks_na['End'], errors='coerce')\n",
    "\n",
    "    # Append the result to the historical_data DataFrame\n",
    "    stock_prices_df = pd.concat([stock_prices_df, stock_ciks_na], ignore_index=True)\n",
    "    print(f'----------stock_prices_df Shape: {stock_prices_df.shape}')\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "    # Print progress every 100 lines\n",
    "    if counter % 1000 == 0:\n",
    "        print(f'\\n\\n\\n-----Processed {counter} lines')\n",
    "\n",
    "        print(f'----------Appending chunk to BQ...')\n",
    "        # Load the DataFrame into BigQuery\n",
    "        load_job = client.load_table_from_dataframe(stock_prices_df, table_ref, job_config=job_config)\n",
    "        # Wait for the load job to complete\n",
    "        load_job.result()\n",
    "        print(f'----------Data appended successfully\\n\\n\\n')\n",
    "\n",
    "        # Reinitialize master_df to not store duplicate info next time this runs\n",
    "        stock_prices_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "## Append last chunk of code that most likely did not get into the if clause since when finished counter % 1000 != 0\n",
    "print(f'\\n\\n\\n-----Processed {counter} lines')\n",
    "\n",
    "print(f'----------Appending chunk to BQ...')\n",
    "# Load the DataFrame into BigQuery\n",
    "load_job = client.load_table_from_dataframe(stock_prices_df, table_ref, job_config=job_config)\n",
    "# Wait for the load job to complete\n",
    "load_job.result()\n",
    "print(f'----------Data appended successfully\\n\\n\\n')\n",
    "\n",
    "# Restore warnings\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# Display the final historical_data DataFrame\n",
    "print(stock_prices_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ade05-8168-4ee3-b841-f5baa33133fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create consecutive lags\n",
    "def calculate_lag(group):\n",
    "    # Find the index of the row where Date equals MnAAnnDate\n",
    "    matching_indices = group.index[group['datadate'] == group['mna_eventdate']].tolist()\n",
    "    \n",
    "    if matching_indices:\n",
    "        # Exact match found\n",
    "        baseline_index = matching_indices[0]\n",
    "    else:\n",
    "        # No exact match, find the first date after MnAAnnDate\n",
    "        after_mna_date = group[group['datadate'] > group['mna_eventdate'].iloc[0]]\n",
    "        if not after_mna_date.empty:\n",
    "            baseline_index = after_mna_date.index[0]\n",
    "        else:\n",
    "            # If no date is after MnAAnnDate, fallback to using the latest date\n",
    "            baseline_index = group.index[-1]\n",
    "    \n",
    "    # Calculate the lag by subtracting the baseline_index from the current index\n",
    "    group['lag'] = group.index - baseline_index\n",
    "    \n",
    "    return group\n",
    "\n",
    "stock_ciks_na = stock_ciks_na.groupby('mna_dealid').apply(calculate_lag).reset_index(drop=True)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
